{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first part of the assignment, IDS 2021-2022\n",
    "In this Jupyter notebook, please, document your results and the way you have obtained them. You can use the attached yaml file to build Python environment for this assignment. Another option (and the easiest way) is to just use the _Python environment_ provided at the beginning of the course and then use *pip install* to install *p_decision_tree* library. You can find the required yaml file in the folder of this assignment. In addition to the _Jupyter notebook_, please submit _one zip-file_ containing all datasets and other outputs you have generated (such as pdf, jpg, and others). Please make sure that the datasets and other outputs are easily identifiable, i.e. use names as requested in the corresponding question.\n",
    "\n",
    "This is the _only_ submission that is required (Jupyter notebook + zip-file). A separate report is _not_ needed and will not be considered for grading. \n",
    "\n",
    "Give your commented Python code and answers in the corresponding provided cells. Make sure to answer all questions in a clear and explicit manner and discuss your outputs. _Please do not change the general structure of this notebook_. You can, however, add additional markdown or code cells if necessary. <b>Please DO NOT CLEAR THE OUTPUT of the notebook you are submitting! </b>\n",
    "\n",
    "<font color=\"red\"> *Please make sure to include the names and matriculation numbers of all group members in the slot provided below.* </font> If a name or a student id is missing, the student will not receive any points.\n",
    "\n",
    "Hint 1: While working on the assignment, you will get a better understanding of the dataset. Feel free to generate additional results and visualizations to support your answers. For example, this might be useful regarding data modification, data simplification, or output interpretation. <font color=\"red\">Ensure that all your claims are supported.</font>\n",
    "\n",
    "Hint 2: <font color=\"red\">Plan your time wisely. </font> A few parts of this assignment may take some time to run. It might be necessary to consider time management when you plan your group work.\n",
    "\n",
    "Hint 3: RWTHmoodle allows multiple submissions, with every new submission overwriting the previous one. <b>Partial submissions are therefore possible and encouraged. </b> This might be helpful in case of technical issues with RWTHMoodle, which may occur close to the deadline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"><b>Student Names and IDs:\n",
    "    \n",
    "    1. Daniel Weißen (427 492)\n",
    "    \n",
    "    2. Felix Meyer (378 959)\n",
    "    \n",
    "    3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Almost all of us have the experience of being stuck in an airport because our flight was delayed or canceled. As a person who knows how to analyze data, we all wondered if we could have predicted it if we had access <b>to</b>  the data. This is your chance to find out.\n",
    "\n",
    "In this assignment, you will perform some analysis on a flight delay dataset. This dataset is provided by the U.S. Department of Transportation's (DOT) Bureau of Transportation Statistics (BTS) which tracks the on-time performance of domestic flights operated by large air carriers. In the following, you can find the definition of some of the features in this dataset.\n",
    "\n",
    "<b>Airline delay.</b> \n",
    "This type of delay pertains to the status within the airline’s control. For example, problems with maintenance and crew, cleaning within the cabin, fueling, and baggage loading could all be contributing factors to a delayed flight. \n",
    "\n",
    "<b>Security delay.</b> \n",
    "Security delay is caused by evacuation of a terminal or concourse, re-boarding of an aircraft because of a security breach, inoperative screening equipment, and/or long lines in excess of 29 minutes at screening areas.\n",
    "\n",
    "<b>Weather delay.</b> \n",
    "Weather delay is caused by extreme or hazardous weather conditions that are forecasted or manifest themselves on point of departure, enroute, or on point of arrival.\n",
    "\n",
    "<b>Late aircraft delay.</b> \n",
    "Arrival delay at an airport due to the late arrival of the same aircraft at a previous airport. The ripple effect of an earlier delay at downstream airports is referred to as delay propagation.\n",
    "\n",
    "<b>Taxi in/out.</b> \n",
    "Taxi time is the total time of an aircraft's movement on the ground.\n",
    "\n",
    "<b>Wheels-off.</b> \n",
    "The time that an aircraft lifts off from the origin airport.\n",
    "    \n",
    "<b>Wheels-on.</b> \n",
    " The time that an aircraft lands at the designated airport.\n",
    "\n",
    "<b> Air time.</b> \n",
    "The time from the moment an aircraft leaves the surface until it comes into contact with the surface at the next point of landing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 0 - Preprocessing of the Dataset \n",
    " Carry out the following preprocessing steps before starting the analysis:\n",
    " - Select 95% of the dataset provided for this assignment by random sampling.\n",
    "     - Use one of the group member's student numbers as a seed.\n",
    "     - Rename the newly generated dataset (which contains 95% of the data) to <b>sampled_data</b>.\n",
    " - If it is not mentioned otherwise, you should always use <b>sampled_data</b> created in this step as input for the questions.\n",
    " \n",
    "<font color=\"red\">Note: Your assignment would not be graded if this step is not done. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pip\n",
    "from p_decision_tree.DecisionTree import DecisionTree\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flights_data = pd.read_csv('./dataset.csv')\n",
    "sampled_data = flights_data.sample(frac=0.95, random_state=427492)\n",
    "\n",
    "sampled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Insights into the Data (20 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting of this Question:\n",
    "We want to make ourselves familiar with the data. To this end, we start with an explorative data analysis. You are more than welcome to provide a deeper analysis and generate more visualizations to understand the data better. Please follow the next two parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Basic data analysis\n",
    "To investigate the data, we take a look at some of the basic statistics and properties of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Unique values: \n",
    "Mention the unique values for cancellation reason in the <b>sampled_data</b>. Also, mention the unique values of this feature where the flights have been cancelled and where the flights have not been cancelled. Explain the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'CANCELLATION_REASON'\n",
    "print('unique values for column \\'{}\\': '.format(key) , sampled_data[key].unique())\n",
    "print('unique values for column \\'{}\\' without cancelled flight: '.format(key) , (sampled_data[sampled_data['CANCELLED'] == 0])[key].unique())\n",
    "print('unique values for column \\'{}\\' with cancelled flight: '.format(key) , (sampled_data[sampled_data['CANCELLED'] == 1])[key].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer: \n",
    "        The unique values are displayed in the above output. \n",
    "        For flights that have not been cancelled, the value is 'N', likely for 'not cancelled'. For cancelled flights the\n",
    "        other possible values appear, but not 'N'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Null values: \n",
    "Remove all the rows with null values from the <b>sampled_data</b>. Let's call this new dataset <b>no_null_data</b>. Show the unique values for cancellation reason in <b>no_null_data</b> and compare them to the unique values in <b>sampled_data</b>. Can you explain the difference? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows with null values\n",
    "no_null_data = sampled_data.dropna()\n",
    "\n",
    "print('unique values for column \\'{}\\': '.format(key) , no_null_data[key].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer: \n",
    "        In the no_null_data dataset, only flights which did not get cancelled appear and therefore the only \n",
    "        unique value for the column 'CANCELLATION_REASON' is 'N'. This happens because information about the flight delay is\n",
    "        missing for all cancelled flights.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Boxplot:\n",
    "Use <b>no_null_data</b> dataset to create a new dataset including all the flights from airline 'EV' which have at least 2 hours but at most 6 hours of delay. Let's call this data <b>ev_data</b>.\n",
    "\n",
    "Use a boxplot to create two datasets from <b>ev_data</b> by finding and removing the outliers from the following attributes:\n",
    "   - Late aircraft delay, call this dataset <b>cleaned_data_late_aircraft</b>,\n",
    "   - Air system delay, call this dataset <b>cleaned_data_air_system</b>.\n",
    "    \n",
    "Note that based on the boxplot, the values greater than the upper-whisker and lower than the lower-whisker are considered as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data for airline and departure delay\n",
    "ev_data = no_null_data.loc[(no_null_data.AIRLINE == 'EV') & (no_null_data.ARRIVAL_DELAY.isin(range(120,360)))]\n",
    "ev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier_min_max(data):\n",
    "    '''return lower and upper bound for outliers'''\n",
    "    q1 = np.quantile(data, 0.25)\n",
    "    q3 = np.quantile(data, 0.75)\n",
    "\n",
    "    iqr = q3-q1\n",
    "\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "\n",
    "    return (lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select and remove outliers from 'LATE_AIRCRAFT_DELAY'\n",
    "ev_data.boxplot(column=['LATE_AIRCRAFT_DELAY'])\n",
    "\n",
    "borders_LAD = get_outlier_min_max(ev_data['LATE_AIRCRAFT_DELAY'])\n",
    "cleaned_data_late_aircraft = ev_data[(ev_data['LATE_AIRCRAFT_DELAY'] >= borders_LAD[0]) & (ev_data['LATE_AIRCRAFT_DELAY'] <= borders_LAD[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and remove outliers from 'AIR_SYSTEM_DELAY'\n",
    "ev_data.boxplot(column=['AIR_SYSTEM_DELAY'], return_type='dict')\n",
    "\n",
    "borders_ASD = get_outlier_min_max(ev_data['AIR_SYSTEM_DELAY'])\n",
    "cleaned_data_air_system = ev_data[(ev_data['AIR_SYSTEM_DELAY'] >= borders_ASD[0]) & (ev_data['AIR_SYSTEM_DELAY'] <= borders_ASD[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Basic statistics: \n",
    "Compare basic statistical features of arrival delay (median, mean, and mode, standard deviation, variance) in the <b>ev_data</b>, <b>cleaned_data_late_aircraft</b>, and <b>cleaned_data_air_system</b>. \n",
    "\n",
    "Interpret the differences for these statistical values between these three datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistic(values, dataset_names):\n",
    "    for i in range(len(dataset_names)):\n",
    "        print(' ', dataset_names[i], ': ', values[i])\n",
    "\n",
    "dataset_names = ['ev_data', 'cleaned_data_late_aircraft', 'cleaned_data_air_system']\n",
    "print('\\nmedian:')\n",
    "print_statistic([ev_data['ARRIVAL_DELAY'].median(), cleaned_data_late_aircraft['ARRIVAL_DELAY'].median(), cleaned_data_air_system['ARRIVAL_DELAY'].median()], dataset_names)\n",
    "print('\\nmean:')\n",
    "print_statistic([ev_data['ARRIVAL_DELAY'].mean(), cleaned_data_late_aircraft['ARRIVAL_DELAY'].mean(), cleaned_data_air_system['ARRIVAL_DELAY'].mean()], dataset_names)\n",
    "print('\\nmode:')\n",
    "print_statistic([ev_data['ARRIVAL_DELAY'].mode()[0], cleaned_data_late_aircraft['ARRIVAL_DELAY'].mode()[0], cleaned_data_air_system['ARRIVAL_DELAY'].mode()[0]], dataset_names)\n",
    "print('\\nstd:')\n",
    "print_statistic([ev_data['ARRIVAL_DELAY'].std(), cleaned_data_late_aircraft['ARRIVAL_DELAY'].std(), cleaned_data_air_system['ARRIVAL_DELAY'].std()], dataset_names)\n",
    "print('\\nvariance:')\n",
    "print_statistic([ev_data['ARRIVAL_DELAY'].var(), cleaned_data_late_aircraft['ARRIVAL_DELAY'].var(), cleaned_data_air_system['ARRIVAL_DELAY'].var()], dataset_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer: median, mean and mode are very similar for all three datasets. However, standard deviation and variance are much lower for the air system dataset. The other two are similar \n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Basic visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Mean visualization: \n",
    "Visualize and compare the mean of arrival delay per month in the <b>no_null_data</b>. Just based on this information, if you prefer the minimum delay, which two months would be a good option to book a ticket and which two months are the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_data.groupby(['MONTH'])['ARRIVAL_DELAY'].mean().plot(title='Mean Arrival Delay by Month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    for minimum delay, I would choose either september or october\n",
    "    the worst months are june and december"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Mean visualization:\n",
    "Visualize and compare the mean of weather delay per month in the <b>no_null_data</b>. Which month has the minimum and which month has the maximum average weatherdelay? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_null_data.groupby(['MONTH'])['WEATHER_DELAY'].mean().plot(title='Mean Weather Delay by Month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for relationship between arrival delay and weather delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(no_null_data.groupby(['MONTH'])['WEATHER_DELAY'].mean(), no_null_data.groupby(['MONTH'])['ARRIVAL_DELAY'].mean(), linestyle='None', marker='o')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer: \n",
    "    minimum weather delay: October\n",
    "    maximum weather delay: February"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Interpretation:\n",
    "Based on the visualization of the two previous tasks, can you detect any possible relationship between the arrival delay and weather delay per month? If yes, please explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    there is a slightly positive relationship between the weather delay and arrival delay with some outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Mean visualization: \n",
    "Now visualize the mean of arrival delay per day of the week (per 7 week days) in each month. Based on this information, which combination of days of week and months should be avoided to decrease the possibility of the arrival delay the most? Provide 5 combinations of days of week and months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think this plot is pretty confusing :D ALso blue & orange appear twice. \n",
    "# However, you can easily see the day month combo with the longest delay, I added an alternative version below\n",
    "\n",
    "plt.figure(figsize=[9,5])\n",
    "for i in range(1, 13):\n",
    "    plot = no_null_data[no_null_data['MONTH'] == i].sort_values(['MONTH','DAY_OF_WEEK']).groupby(['DAY_OF_WEEK'])['ARRIVAL_DELAY'].mean().plot(linestyle='None', marker='o')\n",
    "plot.legend(range(1,13), loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute means by month and weekday\n",
    "ad_by_month_weekday = no_null_data.groupby(['MONTH', 'DAY_OF_WEEK'])['ARRIVAL_DELAY'].mean()\n",
    "print(ad_by_month_weekday[11])\n",
    "print(ad_by_month_weekday[6])\n",
    "print(ad_by_month_weekday[5])\n",
    "\n",
    "# plot results\n",
    "fig, axes = plt.subplots( nrows=3, ncols=4, sharey=True )\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(16)\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        ad_by_month_weekday[i*4+j+1].plot(ax=axes[i,j])\n",
    "        axes[i,j].set_title(months[i*4+j])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    - Mondays in December\n",
    "    - Mondays in June\n",
    "    - Mondays in May\n",
    "    - Tuesday in June\n",
    "    - Sunday in December"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Distribution:\n",
    " In <b>no_null_data</b>, plot the distribution of weather delay for those flights with at least 3 hours of weather delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "sb.displot(no_null_data['WEATHER_DELAY'][no_null_data['WEATHER_DELAY'] >= 180], kde=True)\n",
    "plt.xlim(180, max(no_null_data['WEATHER_DELAY']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Felix: Its also possible to use pandas' hist function:\n",
    "\n",
    "wd_greater_3 = no_null_data[no_null_data['WEATHER_DELAY'] >= 3*60]\n",
    "wd_greater_3.hist(column='WEATHER_DELAY', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Monthly distribution:\n",
    "Plot the monthly distribution of weather delay in one figure where weather delay is more than 3 hours in <b>no_null_data</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Felix: I think they mean a distribution for each month\n",
    "\n",
    "sb.displot(no_null_data[no_null_data['WEATHER_DELAY'] > 180]['MONTH'], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_greater_3.hist(column = 'WEATHER_DELAY', by='MONTH', figsize=(15,15), bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g) Joint distribution:\n",
    "Explore the distribution of weather delay and arrival delay together in the <b>no_null_data</b> for airlines 'EV' and 'VX', considering only the flights that the arrival delay is more than 6 hours. Can you find any similarities or differences among them? Please explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_greater_6 = no_null_data[no_null_data['ARRIVAL_DELAY'] > 6*60]\n",
    "ev_vx_data = ad_greater_6[(ad_greater_6.AIRLINE == 'EV') | (ad_greater_6.AIRLINE == 'VX')]\n",
    "ev_data = ad_greater_6[ad_greater_6.AIRLINE == 'EV']\n",
    "vx_data = ad_greater_6[ad_greater_6.AIRLINE == 'VX']\n",
    "\n",
    "print('order graphs:\\n1. EV and VX\\n2. EV\\n3. VX')\n",
    "sb.jointplot(data=ev_vx_data, x=\"ARRIVAL_DELAY\", y=\"WEATHER_DELAY\", kind=\"hist\")\n",
    "sb.jointplot(data=ev_data, x=\"ARRIVAL_DELAY\", y=\"WEATHER_DELAY\", kind=\"hist\")\n",
    "sb.jointplot(data=vx_data, x=\"ARRIVAL_DELAY\", y=\"WEATHER_DELAY\", kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.jointplot(data=ev_vx_data, x=\"ARRIVAL_DELAY\", y=\"WEATHER_DELAY\", kind=\"kde\", fill=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       Your answer:\n",
    "       One can see \n",
    "       For airline EV, it is noticable, that the bigger the delay is, between ~360-500 min, the more linkely it is, that the delay was caused by the weather. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Todos Question 1 </font>\n",
    "\n",
    "1. add lables to plots\n",
    "2. decide on plots where there are two versions\n",
    "3. flesh out text answers\n",
    "4. document code\n",
    "5. move imports to top??\n",
    "6. double check unit of time in the dataset (minutes vs. hours), now we assume hours in 1) and minutes in 2)\n",
    "7. optional: make plots more beautiful (colors, size etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Decision Trees (10 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting of this Question:\n",
    "We want to buy a ticket from 'UA' airline. As we are not a big fan of flights that have a long delay, we have decided to use a decision tree to find the best time to buy the ticket. Our plan is to use a decision tree to predict the arrival delay. But first, we need to preprocess the data. Please do the following tasks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Data preprocessing: \n",
    "Use <b>no_null_data</b> for this task and filter it such that the resulting dataset contains only the flights from 'UA' airline that has some (non zero) arrival delay. \n",
    "\n",
    "First, discretizing the arrival delay as follows:\n",
    " - if the delay is at most 45 minutes, the value of the new attribute should be 'acceptable_delay',\n",
    " - else, the value of the new attribute should be 'unacceptable_delay',\n",
    " \n",
    "Let's call this new categorical feature 'DELAY'.\n",
    "\n",
    "Second, discretize the distance into two equal-width bins and name them 'short' and 'long'. Let's call this new feature 'DISTANCE_CATEGORY'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_data_UA = no_null_data[(no_null_data['AIRLINE'] == 'UA') & (no_null_data['ARRIVAL_DELAY'] != 0)]\n",
    "no_null_data_UA.loc[no_null_data_UA.ARRIVAL_DELAY <= 45, 'DELAY'] = 'acceptable_delay'\n",
    "no_null_data_UA.loc[no_null_data_UA.ARRIVAL_DELAY > 45, 'DELAY'] = 'unacceptable_delay'\n",
    "no_null_data_UA['DISTANCE_CATEGORY'] = pd.qcut(no_null_data_UA['DISTANCE'], q=2, labels=['short', 'long'])\n",
    "no_null_data_UA = no_null_data_UA.assign(DISTANCE_CATEGORY = pd.cut(no_null_data_UA['DISTANCE'], [0, no_null_data_UA.DISTANCE.max()/2, np.inf], labels=['short', 'long']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Decision tree:\n",
    "Consider the extended dataset from the previous task (task a). Use 'SCHEDULED_DEPARTURE_CATEGORY', 'DISTANCE_CATEGORY', and 'DAY_OF_WEEK' as descriptive features. Generate a decision tree in which the minimum number of samples for splitting is 1000.\n",
    "\n",
    "Note: for this task, you must use p_decision_tree library. You can use the attached yaml file to build Python environment for this task. The easiest way is to just use *pip install*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip.main(['install', 'p_decision_tree'])\n",
    "\n",
    "data = no_null_data_UA[['SCHEDULED_DEPARTURE_CATEGORY', 'DISTANCE_CATEGORY', 'DAY_OF_WEEK', 'DELAY']]\n",
    "columns = data.columns\n",
    "\n",
    "descriptive_features = ['SCHEDULED_DEPARTURE_CATEGORY', 'DISTANCE_CATEGORY', 'DAY_OF_WEEK']\n",
    "label = 'DELAY'\n",
    "\n",
    "# Converting all the columns to string\n",
    "for column in columns:\n",
    "    data[column]= data[column].astype(str)\n",
    "\n",
    "data_descriptive = data[descriptive_features].values\n",
    "data_label = data[label].values\n",
    "\n",
    "# Calling DecisionTree constructor\n",
    "decisionTree = DecisionTree(data_descriptive.tolist(), descriptive_features, data_label, \"entropy\")\n",
    "\n",
    "# set min splitting number to 1000\n",
    "decisionTree.id3(0,1000)\n",
    "\n",
    "# Visualizing decision tree by Graphviz\n",
    "dot = decisionTree.print_visualTree(render=True)\n",
    "\n",
    "# display( dot )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) ID3 feature selection:\n",
    "In the generated decision tree, what is the best feature (based on entropy) for splitting the tree in the second round of ID3 considering the value of the feature chosen in the first round of ID3?       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    DAY_OF_WEEK\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Rule interpretation:\n",
    "Based on the discovered decision tree, which conditions are more prone to more than 45 minutes delay. Explain two rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    - Flights in the afternoon and evening\n",
    "    - Flights during the week\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Classification Models and Prediction (50 Points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background of this Question:\n",
    "You heard from a friend that you are entitled to receive a payment of at least 150€ if your flight is delayed by more than 3 hours. Very excited, you are reminded of your IDS course and the flight dataset you had to analyze back then. You start to imagine a model trained on these flights that can predict if your future flights are delayed by three hours and, basically, allow you to travel the world for free if it chooses these flights correctly. You remember your IDS lecture and what you have to do to make your dream come true: You want to prepare the data accordingly, i.e., you model the target variable of being delayed by more than 3 hours and you choose and model the descriptive variable that you want to use for predicting delay. For the evaluation of your models, you have to choose an evaluation metric that describes whether the flights chosen by your model are actually delayed by <b> at least </b> 3 hours. Moreover, for the models, you want to train different regression, SVM, and neural network models with different parameters and find the best one. In the end, you should calculate for which flight price your model lets you travel the world for free.\n",
    "### Parts of this question:\n",
    "We want you to systematically approach the questions. So we take the following steps (parts): preparing the data, what is the target variable, what are your descriptive variables, what is the evaluation measure you are trying to maximize, and what is the baseline you should at least be better than?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0: Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the classification dataset; i.e., <b>flights_classifying.csv</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "flights_classifying = pd.read_csv('./flights_classifying.csv')\n",
    "flights_classifying.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly order the data points using one of the group member's students as the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "flights_cr = flights_classifying.sample(frac=1, random_state=427492)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Designing your variables and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Target feature:\n",
    "Design your target feature such that you can predict whether a flight is delayed by more than 3 hours or not and add it to the dataset. Drop all data points that contain a canceled flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "flights_cr_clean = flights_cr[flights_cr['CANCELLED'] == False]\n",
    "\n",
    "print(flights_cr_clean.DEPARTURE_DELAY)\n",
    "\n",
    "flights_cr_clean.loc[flights_cr_clean.DEPARTURE_DELAY <= 180, 'DELAY>3h'] = False\n",
    "flights_cr_clean.loc[flights_cr_clean.DEPARTURE_DELAY > 180, 'DELAY>3h'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Descriptive features:\n",
    "Please select your descriptive features and motivate your choice. Always consider the setting and whether choosing these features makes sense concerning the setting of the question. Apply the necessary transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "flights_filtered = flights_cr_clean[['DAY_OF_WEEK', 'AIRLINE',  'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', \n",
    "       'DISTANCE', 'DAY_YEARLY', 'SCHEDULED_DEPARTURE_CATEGORY']]\n",
    "# Chosen features:\n",
    "# All features, which can be obtained from future flights are chosen, because we want to predict for upcoming flights, if there is a delay or not\n",
    "# DAY_OF_WEEK: can be revelant because maybe some weekdays are more prone to delays than others\n",
    "# AIRLINE: maybe certain airline do have more delay than others\n",
    "# ORIGIN-, DESTINATION_AIRPORT: Maybe some airports are not so well organized which can cause delay\n",
    "# DISTANCE: Perhaps for long or short distances the delay is caused more often\n",
    "# DAY_YEARLY: Maybe e.g. in the winter, there is usually more delay than in summer\n",
    "# SCHEDULED_DEPARTURE_CATEGORY: maybe at certain times during the day, there is e.g. more traffic, causing delay\n",
    "\n",
    "flights_descriptive_f = pd.get_dummies(flights_filtered)\n",
    "print(flights_descriptive_f.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split your data into training and testing data, with 85% of the dataset going to testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(flights_descriptive_f, flights_cr_clean['DELAY>3h'], test_size=0.85, random_state=42)\n",
    "y_train_arr = [val for val in y_train]\n",
    "y_test_arr = [val for val in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Evaluation metric\n",
    "Discuss and choose an evaluation metric that you can evaluate your predictions against. Hint: Be aware of the setting of this questions, i.e., what your goal is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you may put code here, if necessary\n",
    "len(flights_cr_clean['DELAY>3h'][flights_cr_clean['DELAY>3h'] == True]) / len(flights_cr_clean['DELAY>3h'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    Since the goal is to save as much money as possible, when choosing a flight, it is important, that the flights, we choose are very likely to have a delay of more than 3h. The precision indicates that. It is not so relevant for us if a flight, which has a delay of more than 3h is not identified as such but on the other hand it is bad, if we incorrectly predict a flight to have a delay of >3h if it doesn't have such a delay, it is bad for us. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Evaluation baseline\n",
    "Calculate the baseline of the evaluation metric, i.e., a value you can achieve without any model by basic data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "y_pred_naiv = [1 if val == True else 0 for val in y_test]\n",
    "print(np.sum(y_pred_naiv)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    The baseline is 6,93%. This is the precision we get if we just predict everything to be positive.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Model Selection\n",
    "\n",
    "For each of the classifiers: regression, SVM and neural network, train a model. For each of these models, select and fine-tune the parameters such that the result w.r.t. your evaluation metric is as good as possible. You have to k-fold cross-validate (reasonable choice of k) your training and you have to test your predictions on the test dataset.\n",
    "\n",
    "Hint: There might be some problems with class imbalance when you fit your models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Regression:\n",
    "Train, finetune and evaluate a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "param_grid = {'C': [0.01, 1],\n",
    "              'penalty': ['l2'],\n",
    "              'class_weight': [{'False': 0.001, 'True': 99.999}, 'balanced'], 'solver': ['liblinear'], }\n",
    "grid_regr = GridSearchCV(LogisticRegression(), param_grid,\n",
    "                         cv=5, verbose=3, scoring='precision')\n",
    "grid_regr.fit(X_train, y_train_arr)\n",
    "print(grid_regr.best_params_)\n",
    "\n",
    "y_pred_regr = grid_regr.predict(X_test)\n",
    "precision_regr = precision_score(y_test_arr, y_pred_regr)\n",
    "print(precision_regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) SVM:\n",
    "Train, finetune and evaluate an SVM.\n",
    "In this task we advise you to use only a subset of the training dataset, i.e., 10000 datapoints, since this is computationally very expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "param_grid = {'kernel': ['poly', 'rbf'], 'C': [0.1, 1], 'class_weight':['balanced']}\n",
    "grid_svm = GridSearchCV(SVC(C=1), param_grid, cv = 5, verbose = 3, scoring='precision') \n",
    "grid_svm.fit(X_train[0:10000], y_train_arr[0:10000])\n",
    "print(grid_svm.best_params_)\n",
    "\n",
    "y_pred_svm = grid_svm.predict(X_test)\n",
    "precision_svm = precision_score(y_test_arr, y_pred_svm)\n",
    "print(precision_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Neural Network:\n",
    "Train, finetune and evaluate a neural network. You do not need to test all the hyper-parameters, just a reasonable amount.\n",
    "\n",
    "Hint: You might encounter some problems due to the class imbalance of delayed and undelayed flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X_train_delay_idx = y_train.index[y_train == True]\n",
    "X_train_no_delay_idx = y_train.index[y_train == True]\n",
    "X_train_delay_idx = X_train_delay_idx.append(X_train_no_delay_idx)\n",
    "\n",
    "X_train_undersample = X_train.loc[list(X_train_delay_idx)]\n",
    "y_train_undersample = y_train.filter(items=X_train_delay_idx, axis=0)\n",
    "\n",
    "param_grid = {\"hidden_layer_sizes\":[(5,), (4,4,)], }\n",
    "grid_mlp = GridSearchCV(MLPClassifier(), param_grid, cv = 5, verbose = 3, scoring='precision') \n",
    "grid_mlp.fit(X_train_undersample, y_train_undersample)\n",
    "print(grid_mlp.best_params_)\n",
    "\n",
    "y_pred_mlp = grid_mlp.predict(X_test)\n",
    "precision_mlp = precision_score(y_test_arr, y_pred_mlp)\n",
    "print(precision_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Final conclusion\n",
    "Describe your results for different models and your performance in comparison to the baseline. Are you able to increase the likelihood of getting a delayed flight with your recommendation in comparison to a random selection? What is the flight price for which your model is profitable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code if needed\n",
    "def plot_roc(fpr, tpr, predictor):\n",
    "    plt.subplots(1, figsize=(10,10))\n",
    "    plt.title('Receiver Operating Characteristic - ' + predictor)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], ls=\"--\")\n",
    "    plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# random guessing:\n",
    "y_pred_random = [bool(random.getrandbits(1)) for val in y_test]\n",
    "fpr_random, tpr_random, _ = roc_curve(y_test_arr, y_pred_random)\n",
    "plot_roc(fpr_random, tpr_random, 'random guessing')\n",
    "print('AUC random guessing: {}'.format(roc_auc_score(y_test_arr, y_pred_random)))\n",
    "\n",
    "fpr_regr, tpr_regr, _ = roc_curve(y_test_arr, y_pred_regr)\n",
    "plot_roc(fpr_regr, tpr_regr, 'regression')\n",
    "print('AUC regression: {}'.format(roc_auc_score(y_test_arr, y_pred_regr)))\n",
    "\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test_arr, y_pred_svm)\n",
    "plot_roc(fpr_svm, tpr_svm, 'SVM')\n",
    "print('AUC SVM: {}'.format(roc_auc_score(y_test_arr, y_pred_svm)))\n",
    "\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_test_arr, y_pred_mlp)\n",
    "plot_roc(fpr_svm, tpr_svm, 'MLP')\n",
    "print('AUC MLP: {}'.format(roc_auc_score(y_test_arr, y_pred_mlp)))\n",
    "\n",
    "print('Precision:')\n",
    "print('regression:{}'.format(precision_regr))\n",
    "print('svm:{}'.format(precision_svm))\n",
    "print('mlp:{}'.format(precision_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([precision_regr, precision_svm, precision_mlp])*150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    Since the regression achieved the highest AUC out of all the classifiers, it is the best performing one.\n",
    "\n",
    "    At a price of <=1,06€, the flight becomes profitable\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Clustering (20 Points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting of this Question:\n",
    "There are different types of delay in the dataset. If a flight is delayed before departure, the pilot might fly faster to compensate for the delay. Due to the type of delay and different characteristics of a flight, it might be possible to compensate for the delay or not. In this task we are going to investigate if the compensation for the delay is possible considering different delay types that occurs during a flight.\n",
    "\n",
    "To prepare the dataset for the analysis, first perform the following steps:\n",
    "\n",
    "- Consider <b>no_null_data</b> from the first question in which the null values of the dataset are removed.\n",
    "- Remove all the flights with more than 600 minutes weather delay <b>or</b> with more than 600 minutes late arrival delay. \n",
    "- Create a new feature, 'AIR_TIME_DELAY' indicating the difference between elapsed time and scheduled time (i.e., 'ELAPSED_TIME' - 'SCHEDULED_TIME'). This feature shows the difference between real and planned duration. Explain what does the negative and positive value of this feature mean?\n",
    "- Name the new dataset as <b>clustering_dataset</b>. Print the number of rows and columns in this dataset. Print the first 10 rows of the dataset such that 'AIR_TIME_DELAY', 'SCHEDULED_TIME', and 'ELAPSED_TIME' are readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "clustering_dataset = no_null_data.loc[(no_null_data['WEATHER_DELAY'] <= 600) & (no_null_data['ARRIVAL_DELAY'] <= 600)]\n",
    "clustering_dataset.head()\n",
    "clustering_dataset['AIR_TIME_DELAY'] = clustering_dataset['ELAPSED_TIME'] - clustering_dataset['SCHEDULED_TIME']\n",
    "\n",
    "print('num cols: {}'.format(len(clustering_dataset.columns)))\n",
    "print('num rows: {}'.format(clustering_dataset.shape[0]))\n",
    "print(clustering_dataset[['AIR_TIME', 'SCHEDULED_TIME', 'ELAPSED_TIME']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    A negative value for AIR_TIME_DELAY means that the flight didn't take as long as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) K-means Clustering\n",
    "Perform k-mean clustering based on the following features: 'AIR_TIME_DELAY', 'WEATHER_DELAY', 'LATE_AIRCRAFT_DELAY'.\n",
    "    Let's start step by step:\n",
    "\n",
    "<!-- * Print minimum and maximum values of the 3 mentioned features in <b>clustering_dataset</b>. According to the minimum and maximum values, is it fair to use them directly for clustering analysis? Explain why?\n",
    "* Create 3 new features, namely \"AIR_TIME_DELAY_SCALED\", \"LATE_AIRCRAFT_DELAY_SCALED\", \"WEATHER_DELAY_SCALED\". For scaling, we recommend well-known Min-Max normalization. For each feature with minimum <I>Min</I> and Maximum <I>Max</I>, the scaled value is x_scaled = (x-Min)/(Max-Min). Print minimum and maximum value of \"AIR_TIME_DELAY_SCALED\", \"LATE_AIRCRAFT_DELAY_SCALED\", \"WEATHER_DELAY_SCALED\". -->\n",
    "- Perform k-means clustering algorithm using k=5 on <b>clustering_dataset</b>. Set the parameters such that the algorithm runs at least 5 times using different centroid seeds. Theoretically, explain why running the algorithm with different centroid seeds is necessary.\n",
    "- What is the centroid of each cluster and the number of samples in it.\n",
    "- Add a new column 'cluster' to <b>clustering_dataset</b>. This column indicates to which cluster each flight belongs. Use 'c1', 'c2', 'c3', 'c4, and 'c5' as cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "kmeans = KMeans(n_clusters=5, n_init=5).fit(clustering_dataset[['AIR_TIME_DELAY', 'WEATHER_DELAY', 'LATE_AIRCRAFT_DELAY']])\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "for i in range(len(kmeans.cluster_centers_)):\n",
    "    print('center: {}'.format(kmeans.cluster_centers_[i]))\n",
    "    filtered_centers = [1 if item == i else 0 for item in kmeans.labels_]\n",
    "    print('num samples: {}'.format(sum(filtered_centers)))\n",
    "\n",
    "clustering_dataset['cluster'] = ['c{}'.format(label) for label in kmeans.labels_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    Because K-Means typically finds a local optimum, if you run it multiple times, the results can change. Therefore it makes sense to increase the exploration\n",
    "\n",
    "    center 1: [-5.1059694   1.2174231  10.75419803]\n",
    "    num samples: 265197\n",
    "    center 2: [ -4.10171065   2.48594351 193.07896831]\n",
    "    num samples: 15085\n",
    "    center 3: [27.20507275  1.39975304  2.55514906]\n",
    "    num samples: 130376\n",
    "    center 4: [  9.19328403 147.96841895   8.08614831]\n",
    "    num samples: 5001\n",
    "    center 5: [-3.47993761  1.11533266 73.47445022]\n",
    "    num samples: 71913"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Visualization and Interpretation\n",
    "Create a 3D plot, consider 'AIR_TIME_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY' as axes and color the flights using the cluster labels.\n",
    "Based on the visualization and your domain knowledge after the analysis that you performed in this assignment, explain the clusters and compare them. You may use any type of visualizations or extract statistical metrics to make your interpretations clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "LABEL_COLOR_MAP = {0 : 'r',\n",
    "                   1 : 'y',\n",
    "                   2 : 'b',\n",
    "                   3 : 'g',\n",
    "                   4 : 'purple'\n",
    "                   }\n",
    "\n",
    "label_color = [LABEL_COLOR_MAP[l] for l in kmeans.labels_]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "zdata = clustering_dataset['AIR_TIME_DELAY']\n",
    "xdata = clustering_dataset['WEATHER_DELAY']\n",
    "ydata = clustering_dataset['LATE_AIRCRAFT_DELAY']\n",
    "\n",
    "ax.scatter3D(xdata, ydata, zdata, c=label_color)\n",
    "ax.view_init(30, -120)\n",
    "ax.set_xlabel(\"WEATHER_DELAY\")\n",
    "ax.set_ylabel(\"LATE_AIRCRAFT_DELAY\")\n",
    "ax.set_zlabel(\"AIR_TIME_DELAY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=clustering_dataset, vars=[\"WEATHER_DELAY\", \"LATE_AIRCRAFT_DELAY\", \"AIR_TIME_DELAY\"], hue=\"cluster\", corner=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "597e13c452502ea241ae2f42facc3f21a019a15575f9b03ce53e2c3b37ad6071"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
