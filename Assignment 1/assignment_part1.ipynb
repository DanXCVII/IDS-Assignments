{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first part of the assignment, IDS 2021-2022\n",
    "In this Jupyter notebook, please, document your results and the way you have obtained them. You can use the attached yaml file to build Python environment for this assignment. Another option (and the easiest way) is to just use the _Python environment_ provided at the beginning of the course and then use *pip install* to install *p_decision_tree* library. You can find the required yaml file in the folder of this assignment. In addition to the _Jupyter notebook_, please submit _one zip-file_ containing all datasets and other outputs you have generated (such as pdf, jpg, and others). Please make sure that the datasets and other outputs are easily identifiable, i.e. use names as requested in the corresponding question.\n",
    "\n",
    "This is the _only_ submission that is required (Jupyter notebook + zip-file). A separate report is _not_ needed and will not be considered for grading. \n",
    "\n",
    "Give your commented Python code and answers in the corresponding provided cells. Make sure to answer all questions in a clear and explicit manner and discuss your outputs. _Please do not change the general structure of this notebook_. You can, however, add additional markdown or code cells if necessary. <b>Please DO NOT CLEAR THE OUTPUT of the notebook you are submitting! </b>\n",
    "\n",
    "<font color=\"red\"> *Please make sure to include the names and matriculation numbers of all group members in the slot provided below.* </font> If a name or a student id is missing, the student will not receive any points.\n",
    "\n",
    "Hint 1: While working on the assignment, you will get a better understanding of the dataset. Feel free to generate additional results and visualizations to support your answers. For example, this might be useful regarding data modification, data simplification, or output interpretation. <font color=\"red\">Ensure that all your claims are supported.</font>\n",
    "\n",
    "Hint 2: <font color=\"red\">Plan your time wisely. </font> A few parts of this assignment may take some time to run. It might be necessary to consider time management when you plan your group work.\n",
    "\n",
    "Hint 3: RWTHmoodle allows multiple submissions, with every new submission overwriting the previous one. <b>Partial submissions are therefore possible and encouraged. </b> This might be helpful in case of technical issues with RWTHMoodle, which may occur close to the deadline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"><b>Student Names and IDs:\n",
    "    \n",
    "    1. Daniel Weißen (427 492)\n",
    "    \n",
    "    2. Felix Meyer (378 959)\n",
    "    \n",
    "    3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Almost all of us have the experience of being stuck in an airport because our flight was delayed or canceled. As a person who knows how to analyze data, we all wondered if we could have predicted it if we had access <b>to</b>  the data. This is your chance to find out.\n",
    "\n",
    "In this assignment, you will perform some analysis on a flight delay dataset. This dataset is provided by the U.S. Department of Transportation's (DOT) Bureau of Transportation Statistics (BTS) which tracks the on-time performance of domestic flights operated by large air carriers. In the following, you can find the definition of some of the features in this dataset.\n",
    "\n",
    "<b>Airline delay.</b> \n",
    "This type of delay pertains to the status within the airline’s control. For example, problems with maintenance and crew, cleaning within the cabin, fueling, and baggage loading could all be contributing factors to a delayed flight. \n",
    "\n",
    "<b>Security delay.</b> \n",
    "Security delay is caused by evacuation of a terminal or concourse, re-boarding of an aircraft because of a security breach, inoperative screening equipment, and/or long lines in excess of 29 minutes at screening areas.\n",
    "\n",
    "<b>Weather delay.</b> \n",
    "Weather delay is caused by extreme or hazardous weather conditions that are forecasted or manifest themselves on point of departure, enroute, or on point of arrival.\n",
    "\n",
    "<b>Late aircraft delay.</b> \n",
    "Arrival delay at an airport due to the late arrival of the same aircraft at a previous airport. The ripple effect of an earlier delay at downstream airports is referred to as delay propagation.\n",
    "\n",
    "<b>Taxi in/out.</b> \n",
    "Taxi time is the total time of an aircraft's movement on the ground.\n",
    "\n",
    "<b>Wheels-off.</b> \n",
    "The time that an aircraft lifts off from the origin airport.\n",
    "    \n",
    "<b>Wheels-on.</b> \n",
    " The time that an aircraft lands at the designated airport.\n",
    "\n",
    "<b> Air time.</b> \n",
    "The time from the moment an aircraft leaves the surface until it comes into contact with the surface at the next point of landing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 0 - Preprocessing of the Dataset \n",
    " Carry out the following preprocessing steps before starting the analysis:\n",
    " - Select 95% of the dataset provided for this assignment by random sampling.\n",
    "     - Use one of the group member's student numbers as a seed.\n",
    "     - Rename the newly generated dataset (which contains 95% of the data) to <b>sampled_data</b>.\n",
    " - If it is not mentioned otherwise, you should always use <b>sampled_data</b> created in this step as input for the questions.\n",
    " \n",
    "<font color=\"red\">Note: Your assignment would not be graded if this step is not done. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "flights_data = pd.read_csv('./dataset.csv')\n",
    "sampled_data = flights_data.sample(frac=0.95, random_state=427492)\n",
    "\n",
    "sampled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Insights into the Data (20 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting of this Question:\n",
    "We want to make ourselves familiar with the data. To this end, we start with an explorative data analysis. You are more than welcome to provide a deeper analysis and generate more visualizations to understand the data better. Please follow the next two parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Basic data analysis\n",
    "To investigate the data, we take a look at some of the basic statistics and properties of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Unique values: \n",
    "Mention the unique values for cancelation reason in the <b>sampled_data</b>. Also, mention the unique values of this feature where the flights have been canceled and where the flights have not been canceled. Explain the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('unique values for column \\'CANCELLATION_REASON\\': ' , sampled_data['CANCELLATION_REASON'].unique())\n",
    "print('unique values for column \\'CANCELLATION_REASON\\' without canceled flight: ' , (sampled_data[sampled_data['CANCELLED'] == 0])['CANCELLATION_REASON'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Null values: \n",
    "Remove all the rows with null values from the <b>sampled_data</b>. Let's call this new dataset <b>no_null_data</b>. Show the unique values for cancelation reason in <b>no_null_data</b> and compare them to the unique values in <b>sampled_data</b>. Can you explain the difference? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_data = sampled_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Boxplot:\n",
    "Use <b>no_null_data</b> dataset to create a new dataset including all the flights from airline 'EV' which have at least 2 hours but at most 6 hours of delay. Let's call this data <b>ev_data</b>.\n",
    "\n",
    "Use a boxplot to create two datasets from <b>ev_data</b> by finding and removing the outliers from the following attributes:\n",
    "   - Late aircraft delay, call this dataset <b>cleaned_data_late_aircraft</b>,\n",
    "   - Air system delay, call this dataset <b>cleaned_data_air_system</b>.\n",
    "    \n",
    "Note that based on the boxplot, the values greater than the upper-whisker and lower than the lower-whisker are considered as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_data = no_null_data.loc[(no_null_data.AIRLINE == 'EV') & (no_null_data.DEPARTURE_DELAY.isin([2,6]))]\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(2,3))\n",
    "plt.boxplot(ev_data['LATE_AIRCRAFT_DELAY'])\n",
    "plt.figure(figsize=(2,3))\n",
    "plt.boxplot(ev_data['AIR_SYSTEM_DELAY'])\n",
    "\n",
    "def get_outlier_min_max(data):\n",
    "    q1 = np.quantile(data, 0.25)\n",
    "    q3 = np.quantile(data, 0.75)\n",
    "\n",
    "    iqr = q3-q1\n",
    "\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "\n",
    "    return (lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "# Selecting the outliers from 'LATE_AIRCRAFT_DELAY'\n",
    "borders_LAD = get_outlier_min_max(ev_data['LATE_AIRCRAFT_DELAY'])\n",
    "cleaned_data_late_aircraft = ev_data[(ev_data['LATE_AIRCRAFT_DELAY'] >= borders_LAD[0]) & (ev_data['LATE_AIRCRAFT_DELAY'] <= borders_LAD[1])]\n",
    "\n",
    "# Selecting the outliers from 'AIR_SYSTEM_DELAY'\n",
    "borders_ASD = get_outlier_min_max(ev_data['AIR_SYSTEM_DELAY'])\n",
    "cleaned_data_air_system = ev_data[(ev_data['AIR_SYSTEM_DELAY'] >= borders_ASD[0]) & (ev_data['AIR_SYSTEM_DELAY'] <= borders_ASD[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Basic statistics: \n",
    "Compare basic statistical features of arrival delay (median, mean, and mode, standard deviation, variance) in the <b>ev_data</b>, <b>cleaned_data_late_aircraft</b>, and <b>cleaned_data_air_system</b>. \n",
    "\n",
    "Interpret the differences for these statistical values between these three datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistic(values, dataset_names):\n",
    "    for i in range(len(dataset_names)):\n",
    "        print(' ', dataset_names[i], ': ', values[i])\n",
    "\n",
    "dataset_names = ['ev_data', 'cleaned_data_late_aircraft', 'cleaned_data_air_system']\n",
    "print('\\nmedian:')\n",
    "print_statistic([ev_data['ARRIVAL_DELAY'].median(), cleaned_data_late_aircraft['ARRIVAL_DELAY'].median(), cleaned_data_air_system['ARRIVAL_DELAY'].median()], dataset_names)\n",
    "print('\\nmean:')\n",
    "print_statistic([ev_data['ARRIVAL_DELAY'].mean(), cleaned_data_late_aircraft['ARRIVAL_DELAY'].mean(), cleaned_data_air_system['ARRIVAL_DELAY'].mean()], dataset_names)\n",
    "print('\\nmode:')\n",
    "print_statistic([ev_data['ARRIVAL_DELAY'].mode()[0], cleaned_data_late_aircraft['ARRIVAL_DELAY'].mode()[0], cleaned_data_air_system['ARRIVAL_DELAY'].mode()[0]], dataset_names)\n",
    "print('\\nstd:')\n",
    "print_statistic([ev_data['ARRIVAL_DELAY'].std(), cleaned_data_late_aircraft['ARRIVAL_DELAY'].std(), cleaned_data_air_system['ARRIVAL_DELAY'].std()], dataset_names)\n",
    "print('\\nvariance:')\n",
    "print_statistic([ev_data['ARRIVAL_DELAY'].var(), cleaned_data_late_aircraft['ARRIVAL_DELAY'].var(), cleaned_data_air_system['ARRIVAL_DELAY'].var()], dataset_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer: \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Basic visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Mean visualization: \n",
    "Visualize and compare the mean of arrival delay per month in the <b>no_null_data</b>. Just based on this information, if you prefer the minimum delay, which two months would be a good option to book a ticket and which two months are the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_data.sort_values('MONTH').groupby(['MONTH'])['ARRIVAL_DELAY'].median().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    for minimum delay, I would choose either september or october\n",
    "    the worst months are june and july or august"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Mean visualization:\n",
    "Visualize and compare the mean of weather delay per month in the <b>no_null_data</b>. Which month has the minimum and which month has the maximum average weatherdelay? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_data.sort_values('MONTH').groupby(['MONTH'])['WEATHER_DELAY'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(no_null_data.sort_values('MONTH').groupby(['MONTH'])['WEATHER_DELAY'].mean(), no_null_data.sort_values('MONTH').groupby(['MONTH'])['ARRIVAL_DELAY'].median(), linestyle='None', marker='o')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer: \n",
    "    minimum weather delay: October\n",
    "    maximum weather delay: Feburary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Interpretation:\n",
    "Based on the visualization of the two previous tasks, can you detect any possible relationship between the arrival delay and weather delay per month? If yes, please explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    there is a slightly positive relationship with some outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Mean visualization: \n",
    "Now visualize the mean of arrival delay per day of the week (per 7 week days) in each month. Based on this information, which combination of days of week and months should be avoided to decrease the possibility of the arrival delay the most? Provide 5 combinations of days of week and months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[9,5])\n",
    "for i in range(1, 13):\n",
    "    plot = no_null_data[no_null_data['MONTH'] == i].sort_values(['MONTH','DAY_OF_WEEK']).groupby(['DAY_OF_WEEK'])['ARRIVAL_DELAY'].mean().plot(linestyle='None', marker='o')\n",
    "plot.legend(range(1,13), loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    - Mondays in Feburary\n",
    "    - Mondays in June\n",
    "    - Mondays in May\n",
    "    - Sundays in Feburary\n",
    "    - Tuesdays in June"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Distribution:\n",
    " In <b>no_null_data</b>, plot the distribution of weather delay for those flights with at least 3 hours of weather delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "sb.displot(no_null_data['WEATHER_DELAY'][no_null_data['WEATHER_DELAY'] >= 180])\n",
    "plt.xlim(180, max(no_null_data['WEATHER_DELAY']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Monthly distribution:\n",
    "Plot the monthly distribution of weather delay in one figure where weather delay is more than 3 hours in <b>no_null_data</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.displot(no_null_data[no_null_data['WEATHER_DELAY'] > 180]['MONTH'], kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g) Joint distribution:\n",
    "Explore the distribution of weather delay and arrival delay together in the <b>no_null_data</b> for airlines 'EV' and 'VX', considering only the flights that the arrival delay is more than 6 hours. Can you find any similarities or differences among them? Please explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.displot([no_null_data['WEATHER_DELAY'][(no_null_data['WEATHER_DELAY'] >= 360) & (no_null_data['AIRLINE'] == 'EV')], no_null_data['ARRIVAL_DELAY'][(no_null_data['ARRIVAL_DELAY'] >= 360) & (no_null_data['AIRLINE'] == 'EV')]])\n",
    "sb.displot([no_null_data['WEATHER_DELAY'][(no_null_data['WEATHER_DELAY'] >= 360) & (no_null_data['AIRLINE'] == 'VX')], no_null_data['ARRIVAL_DELAY'][(no_null_data['ARRIVAL_DELAY'] >= 360) & (no_null_data['AIRLINE'] == 'VX')]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       Your answer:\n",
    "       TODO: update answer\n",
    "       For airline EV, it is noticable, that the bigger the delay is, between ~360-500 min, the more linkely it is, that the delay was caused by the weather. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Decision Trees (10 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting of this Question:\n",
    "We want to buy a ticket from 'UA' airline. As we are not a big fan of flights that have a long delay, we have decided to use a decision tree to find the best time to buy the ticket. Our plan is to use a decision tree to predict the arrival delay. But first, we need to preprocess the data. Please do the following tasks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Data preprocessing: \n",
    "Use <b>no_null_data</b> for this task and filter it such that the resulting dataset contains only the flights from 'UA' airline that has some (non zero) arrival delay. \n",
    "\n",
    "First, discretizing the arrival delay as follows:\n",
    " - if the delay is at most 45 minutes, the value of the new attribute should be 'acceptable_delay',\n",
    " - else, the value of the new attribute should be 'unacceptable_delay',\n",
    " \n",
    "Let's call this new categorical feature 'DELAY'.\n",
    "\n",
    "Second, discretize the distance into two equal-width bins and name them 'short' and 'long'. Let's call this new feature 'DISTANCE_CATEGORY'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_data_UA = no_null_data[(no_null_data['AIRLINE'] == 'UA') & (no_null_data['ARRIVAL_DELAY'] != 0)]\n",
    "no_null_data_UA.loc[no_null_data_UA.ARRIVAL_DELAY <= 45, 'DELAY'] = 'acceptable_delay'\n",
    "no_null_data_UA.loc[no_null_data_UA.ARRIVAL_DELAY > 45, 'DELAY'] = 'unacceptable_delay'\n",
    "no_null_data_UA['DISTANCE_CATEGORY'] = pd.qcut(no_null_data_UA['DISTANCE'], q=2, labels=['short', 'long'])\n",
    "no_null_data_UA['DAY_OF_WEEK'] = no_null_data_UA['DAY_OF_WEEK'].astype(str)\n",
    "no_null_data_UA['DAY_OF_WEEK']\n",
    "# TDOD: length of them are not equal so maybe not equal size bins? however the documentation of qcut says: \"qcut tries to divide up the underlying data into equal sized bins.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Decision tree:\n",
    "Consider the extended dataset from the previous task (task a). Use 'SCHEDULED_DEPARTURE_CATEGORY', 'DISTANCE_CATEGORY', and 'DAY_OF_WEEK' as descriptive features. Generate a decision tree in which the minimum number of samples for splitting is 1000.\n",
    "\n",
    "Note: for this task, you must use p_decision_tree library. You can use the attached yaml file to build Python environment for this task. The easiest way is to just use *pip install*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "from p_decision_tree.DecisionTree import DecisionTree\n",
    "\n",
    "pip.main(['install', 'p_decision_tree'])\n",
    "\n",
    "data = no_null_data_UA[['SCHEDULED_DEPARTURE_CATEGORY', 'DISTANCE_CATEGORY', 'DAY_OF_WEEK', 'DELAY']]\n",
    "columns = data.columns\n",
    "\n",
    "#All columns except the last one are descriptive by default\n",
    "descriptive_features = ['SCHEDULED_DEPARTURE_CATEGORY', 'DISTANCE_CATEGORY', 'DAY_OF_WEEK']\n",
    "#The last column is considered as label\n",
    "label = ['DELAY']\n",
    "\n",
    "#Converting all the columns to string\n",
    "for column in columns:\n",
    "    data[column]= data[column].astype(str)\n",
    "\n",
    "data_descriptive = data[descriptive_features].values\n",
    "data_label = data[label].values\n",
    "\n",
    "#Calling DecisionTree constructor (the last parameter is criterion which can also be \"gini\")\n",
    "decisionTree = DecisionTree(data_descriptive, descriptive_features, data_label, \"entropy\")\n",
    "\n",
    "#Here you can pass pruning features (gain_threshold and minimum_samples)\n",
    "decisionTree.id3(0,1000)\n",
    "\n",
    "#Visualizing decision tree by Graphviz\n",
    "# TODO: broken library? Throws an exception💩\n",
    "dot = decisionTree.print_visualTree(render=True)\n",
    "\n",
    "# When using Jupyter\n",
    "#display( dot )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) ID3 feature selection:\n",
    "In the generated decision tree, what is the best feature (based on entropy) for splitting the tree in the second round of ID3 considering the value of the feature chosen in the first round of ID3?       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Rule interpretation:\n",
    "Based on the discovered decision tree, which conditions are more prone to more than 45 minutes delay. Explain two rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Classification Models and Prediction (50 Points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background of this Question:\n",
    "You heard from a friend that you are entitled to receive a payment of at least 150€ if your flight is delayed by more than 3 hours. Very excited, you are reminded of your IDS course and the flight dataset you had to analyze back then. You start to imagine a model trained on these flights that can predict if your future flights are delayed by three hours and, basically, allow you to travel the world for free if it chooses these flights correctly. You remember your IDS lecture and what you have to do to make your dream come true: You want to prepare the data accordingly, i.e., you model the target variable of being delayed by more than 3 hours and you choose and model the descriptive variable that you want to use for predicting delay. For the evaluation of your models, you have to choose an evaluation metric that describes whether the flights chosen by your model are actually delayed by <b> at least </b> 3 hours. Moreover, for the models, you want to train different regression, SVM, and neural network models with different parameters and find the best one. In the end, you should calculate for which flight price your model lets you travel the world for free.\n",
    "### Parts of this question:\n",
    "We want you to systematically approach the questions. So we take the following steps (parts): preparing the data, what is the target variable, what are your descriptive variables, what is the evaluation measure you are trying to maximize, and what is the baseline you should at least be better than?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0: Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the classification dataset; i.e., <b>flights_classifying.csv</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly order the data points using one of the group member's students as the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Designing your variables and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Target feature:\n",
    "Design your target feature such that you can predict whether a flight is delayed by more than 3 hours or not and add it to the dataset. Drop all data points that contain a canceled flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Descriptive features:\n",
    "Please select your descriptive features and motivate your choice. Always consider the setting and whether choosing these features makes sense concerning the setting of the question. Apply the necessary transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split your data into training and testing data, with 85% of the dataset going to testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Evaluation metric\n",
    "Discuss and choose an evaluation metric that you can evaluate your predictions against. Hint: Be aware of the setting of this questions, i.e., what your goal is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you may put code here, if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Evaluation baseline\n",
    "Calculate the baseline of the evaluation metric, i.e., a value you can achieve without any model by basic data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Model Selection\n",
    "\n",
    "For each of the classifiers: regression, SVM and neural network, train a model. For each of these models, select and fine-tune the parameters such that the result w.r.t. your evaluation metric is as good as possible. You have to k-fold cross-validate (reasonable choice of k) your training and you have to test your predictions on the test dataset.\n",
    "\n",
    "Hint: There might be some problems with class imbalance when you fit your models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Regression:\n",
    "Train, finetune and evaluate a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) SVM:\n",
    "Train, finetune and evaluate an SVM.\n",
    "In this task we advise you to use only a subset of the training dataset, i.e., 10000 datapoints, since this is computationally very expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Neural Network:\n",
    "Train, finetune and evaluate a neural network. You do not need to test all the hyper-parameters, just a reasonable amount.\n",
    "\n",
    "Hint: You might encounter some problems due to the class imbalance of delayed and undelayed flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Final conclusion\n",
    "Describe your results for different models and your performance in comparison to the baseline. Are you able to increase the likelihood of getting a delayed flight with your recommendation in comparison to a random selection? What is the flight price for which your model is profitable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Clustering (20 Points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting of this Question:\n",
    "There are different types of delay in the dataset. If a flight is delayed before departure, the pilot might fly faster to compensate for the delay. Due to the type of delay and different characteristics of a flight, it might be possible to compensate for the delay or not. In this task we are going to investigate if the compensation for the delay is possible considering different delay types that occurs during a flight.\n",
    "\n",
    "To prepare the dataset for the analysis, first perform the following steps:\n",
    "\n",
    "- Consider <b>no_null_data</b> from the first question in which the null values of the dataset are removed.\n",
    "- Remove all the flights with more than 600 minutes weather delay <b>or</b> with more than 600 minutes late arrival delay. \n",
    "- Create a new feature, 'AIR_TIME_DELAY' indicating the difference between elapsed time and scheduled time (i.e., 'ELAPSED_TIME' - 'SCHEDULED_TIME'). This feature shows the difference between real and planned duration. Explain what does the negative and positive value of this feature mean?\n",
    "- Name the new dataset as <b>clustering_dataset</b>. Print the number of rows and columns in this dataset. Print the first 10 rows of the dataset such that 'AIR_TIME_DELAY', 'SCHEDULED_TIME', and 'ELAPSED_TIME' are readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) K-means Clustering\n",
    "Perform k-mean clustering based on the following features: 'AIR_TIME_DELAY', 'WEATHER_DELAY', 'LATE_AIRCRAFT_DELAY'.\n",
    "    Let's start step by step:\n",
    "\n",
    "<!-- * Print minimum and maximum values of the 3 mentioned features in <b>clustering_dataset</b>. According to the minimum and maximum values, is it fair to use them directly for clustering analysis? Explain why?\n",
    "* Create 3 new features, namely \"AIR_TIME_DELAY_SCALED\", \"LATE_AIRCRAFT_DELAY_SCALED\", \"WEATHER_DELAY_SCALED\". For scaling, we recommend well-known Min-Max normalization. For each feature with minimum <I>Min</I> and Maximum <I>Max</I>, the scaled value is x_scaled = (x-Min)/(Max-Min). Print minimum and maximum value of \"AIR_TIME_DELAY_SCALED\", \"LATE_AIRCRAFT_DELAY_SCALED\", \"WEATHER_DELAY_SCALED\". -->\n",
    "- Perform k-means clustering algorithm using k=5 on <b>clustering_dataset</b>. Set the parameters such that the algorithm runs at least 5 times using different centroid seeds. Theoretically, explain why running the algorithm with different centroid seeds is necessary.\n",
    "- What is the centroid of each cluster and the number of samples in it.\n",
    "- Add a new column 'cluster' to <b>clustering_dataset</b>. This column indicates to which cluster each flight belongs. Use 'c1', 'c2', 'c3', 'c4, and 'c5' as cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Visualization and Interpretation\n",
    "Create a 3D plot, consider 'AIR_TIME_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY' as axes and color the flights using the cluster labels.\n",
    "Based on the visualization and your domain knowledge after the analysis that you performed in this assignment, explain the clusters and compare them. You may use any type of visualizations or extract statistical metrics to make your interpretations clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Your answer:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "597e13c452502ea241ae2f42facc3f21a019a15575f9b03ce53e2c3b37ad6071"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
